---
date: "2018-07-01T00:00:00+08:00"
external_link: ""
image:
  caption: Digital twin to drive building performance
  focal_point: Smart
slides: example-slides
summary: How much information should be gathered in the process of M&V, to reach a desired level of confidence in the resulting building energy model. A collaborative project with Professor Godfried Augenbroe (Georgia Institute of Technology).
tags:
- Building Enegy Simulation
title: "Generating certified energy models in Singapore through an M&V framework: A pilot study"
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""
---
An NUS project in collaboration with [Professor Godfried Augenbroe (Georgia Institute of Technology)](https://arch.gatech.edu/people/godfried-l-augenbroe).

With increasing push from the Singapore Building and Construction Authority (BCA) to have buildings in Singapore certified environmentally friendly according to the Green Mark Scheme, there is an urgent need to verify that these “green buildings” are as environmentally friendly as they are purported. In particular, there is an opportunity for measurement and verification (M&V) using building energy models (BEMs) since these models are already required by the Green Mark Scheme to demonstrate the building's energy savings. However, to date, there is no protocol for M&V using BEMs. Standards and guidelines are also vague with respect to model inputs, outputs, data resolution, as well as model fidelity. Moreover, a cost/benefit analysis of the gathering and processing of building data is missing in the current literature. The aim of this study is therefore to provide answers to the question “How much information should be gathered in the process of M&V, to reach a desired level of confidence in the resulting building energy model”. The answers will provide guidance on M&V protocols that lead to certified BEMs.	

To ensure model reliability, an integral part of the M&V process is the calibration of the energy model. However, current BEM calibration has been carried out on an ad hoc basis, with most studies focusing on the automation of the calibration process, using deviation between predicted and measured outcomes as a measure of how ``well calibrated'' the model is. One caveat is that the “calibrated” BEM may not be representative of the actual building performance since various combinations of inputs can produce a small deviation between measured and predicted outcomes. As a result, models calibrated using this approach might be non-identifiable due to over-parameterization, a problem typically neglected in studies that involve BEM calibration. Therefore, an important aspect of this research project is to investigate possible non-identifiability issues in BEM calibration. We hypothesize that low fidelity models can be better calibrated with limited data because they are less likely to be over-parameterized as compared to high fidelity models that typically contain hundreds if not thousands of uncertain or unknown parameters.




